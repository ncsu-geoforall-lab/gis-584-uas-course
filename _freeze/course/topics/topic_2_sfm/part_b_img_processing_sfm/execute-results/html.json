{
  "hash": "b19332a4c1b5de57b3714870085a4381",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nTopic: \"Topic 2: Structure from Motion\"\ntitle: \"B. Imagery processing and structure from motion (SfM)\"\nsubtitle: \"Topic 2: Structure from Motion\"\ndate: 8/28/2024\n\"Assignment Due Date\": 9/30/2024\n---\n\n\n# From images to 3D models: Photogrammetry and Structure from Motion concepts\n\n## Outline\n\n* aerial imagery distortions\n* orthorectification process\n* interior and exterior orientation\n* Bundle Block Adjustment\n* Ground control points (GCP)\n* Image mosaic and point cloud results\n* Structure from motion (SfM)\n\n## Lecture\n\n* Lecture Slides: [Photogrammetry and SfM](lectures/lecture_2b.qmd)\n* Lecture Recording: [Fall 2024]({{< var recordings.topic2.lecture2b >}}) (NCSU Only)\n\n##  Supplemental materials\n\n* Lectures and demos from the 2021 Geological Society of America short course: \n    * [\"Introduction to Structure from Motion Photogrammetry\"](https://opentopography.org/workshops/GSA2021)\n    * [OpenTopography YouTube Course](https://www.youtube.com/playlist?list=PLYqCeHIaz7Pi2jpqsROsk064vmOsMPz9v)\n\n* Y. Furukawa and C. Hernández . [Multi-View Stereo: A Tutorial](http://carlos-hernandez.org/papers/fnt_mvs_2015.pdf). Foundations and TrendsR in Computer Graphics and Vision, vol. 9, no. 1-2, pp. 1–148, 2013.\n\n## Assignment\n<!-- TODO: Update Links -->\n<!-- * [Intro to the assignment (slides)](https://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/lectures/2017_Imagery_Processing_assignment_intro.html#/) -->\n* [Geoprocessing UAS imagery in Agisoft Metashape](assignments/assignment_2b.qmd)\n\n## Homework\n\nPrepare report on generating orthomosaic and Digital Surface Model using images taken by the UAS Trimble UX5 Rover and performing the processing in Agisoft Metashape. Explain the report generated by Agisoft including the data accuracy.\n\n## Structure from Motion Example\n\n\n```{html}\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Structure from Motion Visualization - Correctly Positioned Anchor Points</title>\n    <style>\n        /* body {\n            overflow: hidden;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            height: 100vh;\n            /* background-color: #000; */\n        } */\n\n        canvas {\n            display: block;\n            width: 100%;\n            height: 100%;\n        }\n    </style>\n</head>\n<body>\n    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js\"></script>\n    <script src=\"https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js\"></script>\n    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/simplex-noise/2.4.0/simplex-noise.min.js\"></script>\n    <!-- <script src=\"https://cdnjs.cloudflare.com/ajax/libs/dat-gui/0.7.6/dat.gui.min.js\"></script> -->\n    <script>\n\n        // Create a GUI\n        // const gui = new dat.GUI();\n\n        // Parameters object\n        const params = {\n            numAnchorPoints: 10, // Default number of anchor points\n            terrainSize: 100 // Default terrain size\n        };\n\n        // Add controls to the GUI\n        // gui.add(params, 'numAnchorPoints', 1, 100).name('Anchor Points').onChange(updateAnchorPoints);\n        // gui.add(params, 'terrainSize', 10, 500).name('Terrain Size').onChange(updateTerrain);\n\n        // Function to update anchor points\n        // function updateAnchorPoints(value) {\n        //     // Logic to update the number of anchor points\n        //     // For example, regenerate anchor points based on the new value\n        //     anchorPoints = createAnchorPoints(geometry, value, terrain);\n        // }\n\n        // // Function to update terrain\n        // function updateTerrain(value) {\n        //     // Logic to update the terrain size\n        //     // For example, regenerate the terrain based on the new value\n        //     generateTerrain(value);\n        // }\n\n        // Set up the scene, camera, and renderer\n        const scene = new THREE.Scene();\n        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n        const renderer = new THREE.WebGLRenderer({ antialias: true });\n        renderer.setSize(window.innerWidth, window.innerHeight);\n        document.body.appendChild(renderer.domElement);\n\n        // Add ambient light\n        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);\n        scene.add(ambientLight);\n\n        // Add directional light\n        const directionalLight = new THREE.DirectionalLight(0xffffff, 1);\n        directionalLight.position.set(5, 5, 5).normalize();\n        scene.add(directionalLight);\n\n        // Simplex noise instance\n        const simplex = new SimplexNoise();\n\n        // Create a DSM using PlaneBufferGeometry and subtle simplex noise\n        const widthSegments = 100;\n        const heightSegments = 100;\n        const geometry = new THREE.PlaneBufferGeometry(10, 10, widthSegments, heightSegments);\n\n        // Modify the z-coordinates of the vertices using simplex noise with reduced amplitude\n        const vertices = geometry.attributes.position.array;\n        for (let i = 0; i < vertices.length; i += 3) {\n            const x = vertices[i];\n            const y = vertices[i + 1];\n            vertices[i + 2] = simplex.noise2D(x * 0.3, y * 0.3) / 2.0; // Reduced amplitude for a more subtle terrain\n        }\n\n        const elevationColors = [\n            { value: 0.0, color: new THREE.Color(0x00bfbf) }, // 0% 0 191 191\n            { value: 0.2, color: new THREE.Color(0x00ff00) }, // 20% 0 255 0\n            { value: 0.4, color: new THREE.Color(0xffff00) }, // 40% 255 255 0\n            { value: 0.6, color: new THREE.Color(0xff7f00) }, // 60% 255 127 0\n            { value: 0.8, color: new THREE.Color(0xbf7f3f) }, // 80% 191 127 63\n            { value: 1.0, color: new THREE.Color(0xc8c8c8) }  // 100% 200 200 200\n        ];\n\n        const vertexShader = `\n            varying float vElevation;\n            void main() {\n                vElevation = position.z;\n                gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n            }\n        `;\n\n        const fragmentShader = `\n            uniform vec3 elevationColors[3];\n            varying float vElevation;\n            void main() {\n                vec3 color;\n                if (vElevation < 0.5) {\n                    color = mix(elevationColors[0], elevationColors[1], vElevation * 2.0);\n                } else {\n                    color = mix(elevationColors[1], elevationColors[2], (vElevation - 0.5) * 2.0);\n                }\n                gl_FragColor = vec4(color, 1.0);\n            }\n        `;\n\n        geometry.computeVertexNormals(); // Recompute normals after modifying vertices\n\n        // Colored Terrain\n        // const shaderMaterial = new THREE.ShaderMaterial({\n        //     vertexShader: vertexShader,\n        //     fragmentShader: fragmentShader,\n        //     uniforms: {\n        //         elevationColors: { value: elevationColors.map(e => e.color) }\n        //     }\n        // });\n        // const terrain = new THREE.Mesh(geometry, shaderMaterial);\n\n        // Wired Terrain\n        const material = new THREE.MeshStandardMaterial({ color: 0x228b22, wireframe: true });\n        const terrain = new THREE.Mesh(geometry, material);\n\n        \n        terrain.rotation.x = -Math.PI / 2; // Rotate to make it horizontal\n        scene.add(terrain);\n\n        // Function to create anchor points directly on the DSM's surface\n        function createAnchorPoints(bufferGeometry, numPoints, terrain) {\n            const positions = bufferGeometry.attributes.position.array;\n            const points = [];\n\n            for (let i = 0; i < numPoints; i++) {\n                // Randomly select a vertex from the geometry\n                const index = Math.floor(Math.random() * (positions.length / 3)) * 3;\n\n                // Create a point at this vertex\n                const point = new THREE.Vector3(\n                    positions[index],\n                    positions[index + 1],\n                    positions[index + 2]\n                );\n\n                // Apply the terrain's rotation to the anchor points\n                point.applyMatrix3(terrain.matrixWorld);\n\n                points.push(point);\n            }\n            return points;\n        }\n\n        // Correctly place anchor points on the terrain surface after rotation\n        const anchorPoints = createAnchorPoints(geometry, 50, terrain);\n        const anchorMaterial = new THREE.PointsMaterial({ color: 0xff0000, size: 0.25 });\n        const anchorGeometry = new THREE.BufferGeometry().setFromPoints(anchorPoints);\n\n        const anchorMesh = new THREE.Points(anchorGeometry, anchorMaterial);\n        scene.add(anchorMesh);\n\n        // Function to create a camera representation\n        function createCameraRepresentation(position, color = 0x0000ff) {\n            const cameraGeometry = new THREE.SphereGeometry(0.1, 32, 32);\n            const cameraMaterial = new THREE.MeshBasicMaterial({ color });\n            const cameraMesh = new THREE.Mesh(cameraGeometry, cameraMaterial);\n            cameraMesh.position.copy(position);\n            scene.add(cameraMesh);\n            return cameraMesh;\n        }\n\n        // Create a UAV camera path for two passes\n        // const uavPath1 = [];\n        // const uavPath2 = [];\n        // for (let i = 0; i <= 1; i += 0.01) {\n        //     const x = 5 * (i * 2 - 1);\n        //     const z = 5 * (i * 2 - 1);\n        //     uavPath1.push(new THREE.Vector3(x, 3, z));\n        //     uavPath2.push(new THREE.Vector3(x, 3.5, -z));\n        // }\n\n         // Create realistic UAV camera paths (grid pattern)\n        // const uavPath1 = [];\n        // const uavPath2 = [];\n        // for (let i = -5; i <= 5; i += 0.25) {\n        //     for (let j = -5; j <= 5; j += 0.25) {\n        //         uavPath1.push(new THREE.Vector3(3, 3, j));\n        //         uavPath2.push(new THREE.Vector3(i, 3.5, j));\n        //     }\n        // }const uavCamera2 = createCameraRepresentation(uavPath2[0], 0xff0000);\n\n        // Define the boundaries and step sizes\n        const startX = -5;\n        const endX = 5;\n        const startY = 3;\n        const endY = 3;\n        const startZ = -5;\n        const endZ = 5;\n        const stepSize = 0.25;\n        const rowDistance = 0.25;\n\n        // Create realistic UAV camera paths (lawnmower pattern)\n        const uavPath1 = [];\n        const uavPath2 = [];\n\n        let direction = 1; // 1 for forward, -1 for backward\n\n        for (let z = startZ; z <= endZ; z += rowDistance) {\n            if (direction === 1) {\n                for (let x = startX; x <= endX; x += stepSize) {\n                    uavPath1.push(new THREE.Vector3(x, startY, z));\n                    uavPath2.push(new THREE.Vector3(x, endY, z));\n                }\n            } else {\n                for (let x = endX; x >= startX; x -= stepSize) {\n                    uavPath1.push(new THREE.Vector3(x, startY, z));\n                    uavPath2.push(new THREE.Vector3(x, endY, z));\n                }\n            }\n            direction *= -1; // Change direction at the end of each row\n        }\n\n        // Create geometry and add points from uavPath1\n        const uavlineGeometry = new THREE.BufferGeometry().setFromPoints(uavPath1[0]);\n\n        // Create a dashed line material\n        const uavlineMaterial = new THREE.LineDashedMaterial({\n            color: 0xff0000, // Red color\n            dashSize: 0.1, // Length of dashes\n            gapSize: 0.1, // Length of gaps between dashes\n        });\n\n        // Create the line object\n        const uavLine = new THREE.Line(uavlineGeometry, uavlineMaterial);\n        uavLine.computeLineDistances(); // Required for dashed lines\n\n        // Add the line to the scene\n        scene.add(uavLine);\n\n        // Create a box to represent the UAV's field of view\n        // const boxGeometry = new THREE.BoxGeometry(1, 1, 1);\n        // const boxMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00, wireframe: true });\n        // const uavFOVBox = new THREE.Mesh(boxGeometry, boxMaterial);\n        // scene.add(uavFOVBox);\n\n        // Create a plane to represent the UAV's field of view\n        const planeGeometry = new THREE.PlaneGeometry(2, 2); // Adjust size as needed\n        const planeMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00, side: THREE.DoubleSide }); // Solid fill color\n        const uavFOVPlane = new THREE.Mesh(planeGeometry, planeMaterial);\n        scene.add(uavFOVPlane);\n\n        // // Create a plane to represent the UAV's field of view\n        //     const aggPlaneGeometry = new THREE.PlaneGeometry(2, 2); // Adjust size as needed\n        //     const aggPlaneMaterial = new THREE.MeshBasicMaterial({ color: 0xffffff, side: THREE.DoubleSide, wireframe: true }); // Solid fill color\n        //     const aggUavFOVPlane = new THREE.Mesh(aggPlaneGeometry, aggPlaneMaterial);\n        //     scene.add(aggUavFOVPlane)\n\n        // Define initial position and rotation\n        const initialPosition = new THREE.Vector3(0, 0, 0);\n        const initialRotation = new THREE.Euler(-Math.PI / 2, 0, 0);\n\n        let uavIndex = 0;\n        const uavCamera1 = createCameraRepresentation(uavPath1[0], 0xff0000);\n        const uavCamera2 = createCameraRepresentation(uavPath2[0], 0x0000ff);\n        \n\n        // Camera frustum visualization for UAV cameras\n        const uavFrustum1 = new THREE.CameraHelper(camera);\n        const uavFrustum2 = new THREE.CameraHelper(camera);\n        scene.add(uavFrustum1);\n        scene.add(uavFrustum2);\n\n        // Function to create and return line between two points\n        function createLine(pointA, pointB, color = 0xffffff) {\n            const geometry = new THREE.BufferGeometry().setFromPoints([pointA, pointB]);\n            const material = new THREE.LineBasicMaterial({ color });\n            const line = new THREE.Line(geometry, material);\n            scene.add(line);\n            return line;\n        }\n\n        // Store the lines for each pass\n        const linesPass1 = [];\n        const linesPass2 = [];\n\n        // Create lines from the UAV cameras to anchor points\n        anchorPoints.forEach(point => {\n            linesPass1.push(createLine(uavPath1[0], point, 0xff00ff));\n            linesPass2.push(createLine(uavPath2[0], point, 0x00ffff));\n        });\n\n        // Simulate feature matching between passes\n        function createFeatureMatchingLines(pointsA, pointsB, color = 0xffd700) {\n            pointsA.forEach((pointA, index) => {\n                const pointB = pointsB[index];\n                const lineGeometry = new THREE.BufferGeometry().setFromPoints([pointA, pointB]);\n                const lineMaterial = new THREE.LineBasicMaterial({ color });\n                const line = new THREE.Line(lineGeometry, lineMaterial);\n                scene.add(line);\n            });\n        }\n\n        // Create feature matching lines between two UAV passes\n        createFeatureMatchingLines(anchorPoints, anchorPoints);\n\n        // OrbitControls for user interaction\n        const controls = new THREE.OrbitControls(camera, renderer.domElement);\n        controls.enableDamping = true;\n        controls.dampingFactor = 0.25;\n        controls.enableZoom = true;\n\n        camera.position.z = 15;\n\n        let lastUpdateTime = 0;\n        const updateInterval = 50; // Time in milliseconds between updates\n        function animate(t) {\n            requestAnimationFrame(animate);\n            // Calculate the time elapsed since the last update\n            const elapsedTime = t - lastUpdateTime;\n\n            if (elapsedTime >= updateInterval) {\n            // Move the UAV cameras along their paths\n            uavIndex = (uavIndex + 1) % uavPath1.length;\n            uavCamera1.position.copy(uavPath1[uavIndex]);\n            uavCamera2.position.copy(uavPath2[uavIndex]);\n\n            if (uavIndex < uavPath1.length - 1) {\n                uavIndex++;\n                const newPoints = uavPath1.slice(0, uavIndex + 1);\n                uavlineGeometry.setFromPoints(newPoints);\n                uavLine.computeLineDistances(); // Required for dashed lines\n            }\n\n            // Update the positions of the lines to keep them connected to the moving UAV cameras\n            linesPass1.forEach((line, index) => {\n                const linePositions = line.geometry.attributes.position.array;\n                const anchorPoint = anchorPoints[index];\n\n                // Update the line's start point (UAV camera position)\n                linePositions[0] = uavCamera1.position.x;\n                linePositions[1] = uavCamera1.position.y;\n                linePositions[2] = uavCamera1.position.z;\n\n                // Update the line's endpoint (anchor point on the terrain)\n                linePositions[3] = anchorPoint.x;\n                linePositions[4] = anchorPoint.y;\n                linePositions[5] = anchorPoint.z;\n\n                line.geometry.attributes.position.needsUpdate = true;\n            });\n\n            linesPass2.forEach((line, index) => {\n                const linePositions = line.geometry.attributes.position.array;\n                const anchorPoint = anchorPoints[index];\n\n                // Update the line's start point (UAV camera position)\n                linePositions[0] = uavCamera2.position.x;\n                linePositions[1] = uavCamera2.position.y;\n                linePositions[2] = uavCamera2.position.z;\n\n                // Update the line's endpoint (anchor point on the terrain)\n                linePositions[3] = anchorPoint.x;\n                linePositions[4] = anchorPoint.y;\n                linePositions[5] = anchorPoint.z;\n\n                line.geometry.attributes.position.needsUpdate = true;\n            });\n\n            // // Update the UAV's field of view box position\n            // uavFOVBox.position.copy(uavCamera1.position);\n\n            //  // Create a plane to represent the UAV's field of view\n            const aggPlaneGeometry = new THREE.PlaneGeometry(2, 2); // Adjust size as needed\n            const aggPlaneMaterial = new THREE.MeshBasicMaterial({ color: 0xffffff, side: THREE.DoubleSide, wireframe: true }); // Solid fill color\n            const aggUavFOVPlane = new THREE.Mesh(aggPlaneGeometry, aggPlaneMaterial);\n            scene.add(aggUavFOVPlane);\n\n            // TODO: Figure out how to reset the aggUavFOVPlane at the end of the uav path\n    \n\n            // Update the UAV's field of view plane position and orientation\n            aggUavFOVPlane.position.set(uavCamera1.position.x, 0, uavCamera1.position.z); // Set y to 0 to place it on the terrain surface\n            aggUavFOVPlane.rotation.x = -Math.PI / 2; // Rotate to align with the terrain surface\n\n            // Update the UAV's field of view plane position and orientation\n            uavFOVPlane.position.set(uavCamera1.position.x, 0, uavCamera1.position.z); // Set y to 0 to place it on the terrain surface\n            uavFOVPlane.rotation.x = -Math.PI / 2; // Rotate to align with the terrain surface\n\n           \n            // Update the last update time\n            lastUpdateTime = t;\n            }\n  \n             controls.update();\n            renderer.render(scene, camera);\n            \n        }\n\n        window.addEventListener('resize', () => {\n            const width = window.innerWidth;\n            const height = window.innerHeight;\n            renderer.setSize(width, height);\n            camera.aspect = width / height;\n            camera.updateProjectionMatrix();\n        });\n\n        animate();\n    </script>\n</body>\n</html>\n```\n\n",
    "supporting": [
      "part_b_img_processing_sfm_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}