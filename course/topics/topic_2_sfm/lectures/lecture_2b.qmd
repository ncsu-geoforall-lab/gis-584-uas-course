---
title: "Imagery Processing"
subtitle: "Center for Geospatial Analytics at North Carolina State University"
author: "Justyna Jeziorska, Helena Mitasova & Corey White"
format:
  revealjs:
    theme: [simple, ../../../../theme.scss]
---

## Objectives

- **Understand** the photogrammetric data processing as a multistep process;
- **Indicate** data needed for orthophoto/DTM generation from aerial imagery;
- **Understand** the difference between interior and exterior orientation of the photo;
- **Describe** the workflow of geoprocessing of aerial imagery in designated software (Agisoft Metashape Professional);

---

## Photogrammetric process

![](../images/photogrammetric_proces.webp)

---

## Photogrammetric process

![](../images/flowchart_processing.webp)

## Data processing

![](../images/flowchart_processing_plain.webp)

---

## UAS data 

### What do we get after the flight mission?

![](../images/uas_data.webp)

---

## Digital imagery

![](../images/digital_imagery.webp)

- usually on the camera SD card
- can be geotagged (depends on camera)
    - Camera lens location is "written into" each photo's EXIF file
    - this is not necessarily the case...

---

## Flight log

- Onboard Inertial Measurement Unit (IMU) accurately measures the orientation of airborne sensors,
- Information is logged into a text file (flight log),
- Contains elements of exterior orientation (EO, more [later in the lecture](./2017_Imagery_Processing.html#/18))

![](../images/log.webp){ width=80% }

---

## GCP coordinates

::: {.columns}
::: {.column width="50%"}

- Measured by GPS coordinates of the panels set before the flight
- Photo ID points (distinguishable ground features) can be surveyed later on 
- It is important to know the GCPs coordinate system (spatial reference system)

::: 
::: {.column width="50%"}

![](../images/GCPs.webp)

::: 
::: 

---

## Spatial reference system {.smaller}

::: {.columns}
::: {.column width="50%"}

- Defines how the two-dimensional, projected map in your GIS is related to real places on the earth
- It is crucial to know what is your data reference system!

::: 
::: {.column width="50%"}

![](../images/projection.webp){ width=60% }

::: 
::: 

- There are global map projections, but most map projections are created and optimized to project smaller areas of the earth’s surface
- There are two different types of coordinate reference systems: Geographic Coordinate Systems and Projected Coordinate Systems
- [Spatial reference list (EPSG codes for coordinate reference systems)](http://spatialreference.org/ref/epsg/)

---

## UAS data processing outputs

### What do we get after processing the data?

![](../images/processing_outputs.webp)

---

## Orthophoto

::: {.columns}
::: {.column width="50%"}

- Aerial imagery geometrically corrected ("orthorectified") such that the scale is uniform
- Raster: consists of red, green, and blue bands

::: 
::: {.column width="50%"}

![](../images/ortho_example.webp)

::: 
::: 

---

## Digital Surface Model {.smaller}



- **DEM/DTM - Digital Elevation Model / Digital Terrain Model**
    - Representation of a terrain's elevation
    - Bare-earth raster grid
- **DSM - Digital Surface Model** 
    - Representation of a visible surface
    - Captures the natural and built features on the Earth’s surface

![](../images/dtm_dsm.webp){ width=100% }

---

## Pointcloud

- Representation of the external surface of an object
- Set of vertices in a three-dimensional coordinate system
- Vector or raster?
- Dale Lutz once said, "point cloud is a badly behaved raster"

::: {.columns}
::: {.column width="50%"}

![](../images/pointclouds.webp)

::: 
::: {.column width="50%"}

![](../images/Point_cloud_torus.webp)

::: 
::: 

---

## Multiple-view geometry

- **Scene geometry (structure):**  
  Given 2D point matches in two or more images, where are the corresponding points in 3D?
- **Correspondence (stereo matching):**  
  Given a point in just one image, how does it constrain the position of the corresponding point in another image?
- **Camera geometry (motion):**  
  Given a set of corresponding points in two or more images, what are the camera matrices for these views?

---

## What do we need?

1. Digital **imagery**;
2. (Digital elevation model or topographic dataset);
3. Exterior **orientation parameters** from aerial triangulation or IMU;
4. (Camera calibration report);
5. (Ground Control Points parameters);
6. Photogrammetric **processing software** that utilizes collinearity equations.

<p class="small">Items in brackets are optional</p>

---

## Digital imagery {.smaller}

![](../images/digital_imagery.webp)

::: {.columns}
::: {.column width="50%"}

![](../images/multiview.webp)

::: 
::: {.column width="50%"}

![](../images/camera_sensor.webp){ width=80% }

::: 
::: 

---

<!-- ## Digital Elevation Model {.smaller}

::: {.columns}
::: {.column width="50%"}

![](../images/disortion.webp)

::: 
::: {.column width="50%"}

**In the past:** Shape of the ground surface must be known in order to remove the effects of relief displacement

**Now:** Computed automatically by Structure from Motion

::: 
::: 

--- -->

## Structure from Motion (SfM) {.smaller}

::: {.columns}
::: {.column width="50%"}

- Range imaging technique
- Process of estimating 3D structures from 2D image sequences
- May be coupled with local motion signals

::: 
::: {.column width="50%"}

![](../images/sfm_explained.webp)

::: 
::: 

---

## Exterior orientation (EO) {.smaller}

**EO =** Position and orientation in the object space

6 elements **necessary** for any photogrammetric processing:

::: {.columns}
::: {.column width="50%"}

- X, Y, and Z of the exposure station position (latitude, longitude, and altitude of the camera)
- Angular orientation: ω, φ, and κ (yaw, pitch, and roll)

::: 
::: {.column width="50%"}

![](../images/orientation.webp)

::: 
::: 

---

## Flight log {.smaller}

- Log file contains elements of exterior orientation that are measured by onboard Inertial Measurement Unit (IMU) and written into a text file

![](../images/log.webp){ width=60% }

- Sometimes (most DJI products) exterior orientation parameters are saved in photos' EXIF file
- Log contains information about the location of the camera, not the location of the depicted object - [more info in this section of lecture 3](./HM_Photogrammetry_and_SfM.html#/25)

---

## Interior orientation {.smaller}

::: {.columns}
::: {.column width="50%"}

- In the past: camera calibration report
- Now: Self-calibration (auto-calibration) is the process of determining intrinsic camera parameters directly from uncalibrated images

::: 
::: {.column width="50%"}

![](../images/interior_orientation.webp)

::: 
::: 

- Can be automatically derived using Structure from Motion (SfM) methods

---

## Ground Control Points {.smaller}

::: {.columns}
::: {.column width="50%"}

- **GCP** - Target in the project area with known 3 coordinates (X, Y, Z or lat, long, alt)
- For more information about placing targets and importance of GCPs see [this section of lecture 3](./HM_Photogrammetry_and_SfM.html#/30)
- For more information about processing the data with GCPs see [intro to the assignment](./2017_Imagery_Processing_assignment_intro.html)

::: 
::: {.column width="50%"}

![](../images/GCP_girls.webp)

::: 
::: 

---

## Processing options

![](../images/processing_options.webp)

---

## Processing options

Everything boils down to... money (and time)

- What is my starting budget and equipment?
- How frequently will I fly?
- Do I have the experience/training necessary for processing (or am I able to hire people who do)?
- Do I have time to process the data by myself?

---

## Processing options - software

- [Agisoft Metashape](http://www.agisoft.com/)
- [Pix4D](https://pix4d.com/)
- [Trimble Business Center](http://uas.trimble.com/tbc-am) - Aerial Photogrammetry Module
- [Drone2Map (ESRI)](http://www.esri.com/products/drone2map)
- [DroneMapper](https://dronemapper.com/)
- [OpenDroneMap](http://opendronemap.org/)
- many many more...

---

<!-- ## Agisoft Metashape Professional {.smaller}

::: {.columns}
::: {.column width="50%"}

- Image-based solution aimed at creating 3D content from still images
- Operates with arbitrary images and is efficient in both controlled and uncontrolled conditions
- Both image alignment and 3D model reconstruction are fully automated

::: 
::: {.column width="50%"}

- [Installer](http://www.agisoft.com/downloads/installer/)
- [Manual](https://www.agisoft.com/pdf/metashape-pro_1_5_en.pdf)
- Tutorials for:
  - [Orthophoto and DSM generation with GCPs](http://www.agisoft.com/pdf/PS_1.3%20-Tutorial%20%28BL%29%20-%20Orthophoto,%20DEM%20%28GCPs%29.pdf)
  - [Dense Cloud Classification & DTM Generation](https://agisoft.freshdesk.com/support/solutions/articles/31000148866-dense-cloud-classification)
  - [DEM based Measurements](https://agisoft.freshdesk.com/support/solutions/articles/31000148884-dem-based-measurements-)
- [YouTube channel](https://www.youtube.com/channel/UCPheXwPeFLnWHo8u4ksSH7w)

![](../images/Agisoft_Logo.webp){ width=30% }

::: 
::: 

---

## Processing workflow {.smaller}

![](../images/flowchart_processing_plain.webp)

### Preprocessing stage:

![](../images/flowchart_processing_pre.webp)

- Loading photos into Metashape
- Inspecting loaded images, removing unnecessary images

---

## Processing workflow {.smaller}

### Processing stage:

![](../images/flowchart_processing_exporting.webp)

1. Aligning photos
2. Building dense point cloud
    - (optional: editing dense point cloud)
3. Building mesh (3D polygonal model)
    - (optional: editing mesh)
4. Generating texture
5. Building DSM and orthomosaic

---

## Exporting results

![](../images/flowchart_processing_ex.webp)

![](../images/processing_outputs.webp)

---

## Preprocessing

- Loading photos
- Loading camera positions (flight log)
- If the EO is in the photos EXIF file, the parameters will load automatically

![](../images/camera_positions.webp){ width=70% }

---

## Aligning photos {.smaller}

At this stage, Agisoft Metashape implements SfM algorithms to monitor the movement of features through a sequence of multiple images:

::: {.columns}
::: {.column width="50%"}

- Obtains the relative location of the acquisition positions
- Refines camera calibration parameters
- **Sparse point cloud** and a set of **camera positions** are formed

::: 
::: {.column width="50%"}

![](../images/aligning_photos_funny.webp){ width=60% }

::: 
::: 

---

## Bundle Block Adjustment {.smaller}

::: {.columns}
::: {.column width="50%"}

- Non-linear method for refining structure and motion
- Minimizing reprojection error
- Detecting image feature points (i.e., various geometrical similarities such as object edges or other specific details)

::: 
::: {.column width="50%"}

![](../images/bundle_block_adjustment.webp)

::: 
::: 

---

## Bundle Block Adjustment {.smaller}

::: {.columns}
::: {.column width="50%"}

- Subsequently monitoring the movement of those points throughout the sequence of multiple images
- Using this information as input, the locations of those feature points can be estimated and rendered as a sparse 3D point cloud

::: 
::: {.column width="50%"}

![](../images/Bundle_Block_Adjustment2.webp)

::: 
::: 

---

## Aligning cameras in Metashape {.smaller}

::: {.columns}
::: {.column width="50%"}

![](../images/aligned_photos.webp){ width=58.5% }

::: 
::: {.column width="50%"}

![](../images/sparse_cloud.webp){ width=39% }

<p class="small"><strong>Sparse point cloud</strong> generation</p>

::: 
::: 

**Accuracy**

- **High** accuracy setting > more accurate camera position estimates (time-consuming)
- **Low** accuracy setting > rough camera positions

---

## Building dense point cloud {.smaller}

At the stage of dense point cloud generation, Agisoft calculates depth maps for every image

- Quality: **Highest, High, Medium, Low, Lower** > the higher quality, the more accurate camera position estimates, but the process is more time-consuming

![](../images/sparse_cloud.webp){ width=40% }

![](../images/arrows.webp){ width=10% }

![](../images/dense_cloud.webp){ width=40% }

---

## Building dense point cloud {.smaller}

### Depth Filtering modes

Algorithms sorting outliers (due to some factors, like poor texture of some elements of the scene, noisy or badly focused images)

- **Mild** depth filtering mode > for **complex geometry** (numerous small details on the foreground), for important features not to be sorted out
- **Aggressive** depth filtering mode > sorting out most of the outliers
- **Moderate** depth filtering mode > results in between the Mild and Aggressive

---

## Optional: Editing dense point cloud {.smaller}

::: {.columns}
::: {.column width=60%"}

- Manual points removal
- Automatic filtering based on applied masks
- Sparse cloud only:
  - Reducing the number of points in the cloud by setting tie point per photo limit
  - Automatic filtering based on:
    - Reprojection error
    - Reconstruction uncertainty
    - Image count

::: 
::: {.column width="40%"}

![](../images/editing_pointcloud.webp)

::: 
::: 

---

## Building mesh {.smaller}

::: {.columns}
::: {.column width="50%"}

- **Arbitrary** > for modeling of any kind of object
  - Should be selected for closed objects (statues, buildings, etc.)
  - Memory consumption: high

::: 
::: {.column width="50%"}

![](../images/mesh.webp){ width=65% }

::: 
::: 

::: {.columns}
::: {.column width="50%"}

- **High field** > for modeling of planar surfaces
  - Should be selected for aerial photography
  - Memory consumption: low
  - Allows for larger data sets processing

::: 
::: 

---

## Building mesh {.smaller}

::: {.columns}
::: {.column width="50%"}

- **Source data** > the source for the mesh generation
  - **Sparse cloud** > fast 3D model generation (low quality)
  - **Dense cloud** > high-quality output based on the previously reconstructed dense point cloud
- **Face count** > the maximum face count in the final mesh

::: 
::: {.column width="50%"}

![](../images/mesh_low.webp)

![](../images/mesh_high.webp)

::: 
::: 

---

## Optional: Editing mesh {.smaller}

::: {.columns}
::: {.column width="50%"}

- **Close Holes tool** > repairs your model if the reconstruction procedure resulted in a mesh with several holes, due to **insufficient image overlap**
  - Necessary step for **volumes calculation**

::: 
::: {.column width="50%"}

![](../images/close_holes.webp)

::: 
::: 

- **Decimation tool** > decreases the geometric resolution of the model by replacing a high-resolution mesh with a lower resolution one

---

## Optional: Editing mesh {.smaller}

::: {.columns}
::: {.column width="60%"}

- **Automatic filtering** based on specified criteria:
  - Connected component size
  - Polygon size
- Manual polygon removal
- Fixing mesh topology
- **Editing mesh in the external program**
  - Export mesh for editing in the external program
  - Import edited mesh

::: 
::: {.column width="40%"}

![](../images/mesh_editing.webp){ width=80% }

![](../images/mesh_editing2.webp){ width=80% }

::: 
::: 

---

## Generating texture {.smaller}

- Determines how the object texture will be packed in the texture atlas
- Affects the quality of the final model

::: {.columns}
::: {.column width="50%"}

![](../images/texture.webp){ width=80% }

::: 
::: {.column width="50%"}

- **Texture mapping modes:**
  - Generic
  - Adaptive orthophoto
  - Orthophoto
  - Spherical
  - Single photo
  - Keep uv

::: 
::: 

---

## Texture mapping modes {.smaller}

### Generic

- Creates as uniform texture as possible

### Adaptive orthophoto

- The object surface split into the flat part and vertical regions
- The flat part of the surface textured using the orthographic projection, 
  while vertical regions textured separately to maintain accurate texture representation in such regions
- More compact texture representation for nearly planar scenes + good texture quality 
  for vertical surfaces

---

## Texture mapping modes {.smaller}

#### Orthophoto

- The whole object surface textured in the orthographic projection
- Even more compact texture representation than the Adaptive orthophoto at
  the expense of texture quality in vertical regions

#### Spherical

- Only for objects that have a ball-like form

#### Single photo

- Texture from a single photo (photo can be selected from 'Texture from' list)

#### Keep uv

- Generates texture atlas using current texture parametrization; Rebuilding current texture with different resolution or generating
  the atlas parametrized in the external software

---

## Generating DSM {.smaller}

::: {.columns}
::: {.column width="50%"}

![](../images/build_DEM.webp)

::: 
::: {.column width="50%"}

### Parameters {.smaller}

- **Source data:** Dense point cloud
- **Interpolation**
  - Disabled: leads to accurate reconstruction results since only areas corresponding to dense point cloud points are reconstructed
  - Enabled (recommended): Interpolation mode - Agisoft will calculate DEM for all areas of the scene that are visible on at least one image.

::: 
::: 

---

## Generating orthophoto {.smaller}

::: {.columns}
::: {.column width="40%"}

![](../images/build_ortho.webp){ width=70% }

::: 
::: {.column width="60%"}

### Parameters

- **Surface:** DEM
- **Blending mode**
  - Mosaic (default): Implements an approach with data division into several frequency domains, which are blended independently
  - Average: Uses the weighted average value of all pixels from individual photos
  - Disabled: The color value for the pixel is taken from the photo with the camera view being almost along the normal to the reconstructed surface in that point.

::: 
::: 

---

## Exporting results & saving intermediate results

#### Orthophoto export

::: {.columns}
::: {.column width="50%"}

![](../images/ortho_example.webp)

::: 
::: 

---

## Exporting results & saving intermediate results

#### DEM export

::: {.columns}
::: {.column width="50%"}

![](../images/DSM.webp){ width=150% }

::: 
::: 

---

## Exporting results & saving intermediate results

#### 3D model export

::: {.columns}
::: {.column width="50%"}

![](../images/sketchfab.webp){ width=72% }

::: 
::: 

---

## Exporting results & saving intermediate results

#### Point cloud export

::: {.columns}
::: {.column width="50%"}

![](../images/pointcloud.webp)

::: 
::: 

---

## Exporting results & saving intermediate results {.smaller}

### Processing report generation

::: {.columns}
::: {.column width="50%"}

![](../images/report_1.webp){ width=60% }

![](../images/report_2.webp){ width=60% }

::: 
::: 

---

## Processing report {.smaller}

::: {.columns}
::: {.column width="60%"}

### Includes:

- Orthophoto and digital elevation model sketch
- Camera parameters and survey scheme
- Tie points data export (matching points and panoramas)
- Image overlap statistics
- Camera positioning error estimates
- Ground control point error estimates

::: 
::: {.column width="40%"}

![](../images/Agisoft_report.webp){ width=90% }

::: 
::: 

---

## Batch processing

![](../images/Agisoft_batch.webp)

---

## Quality processing with GCPs {.smaller}

- Marker positions are defined by their projections on the source photos
- After optimizing alignment based on markers, Point cloud generation and other steps need to be performed
  - Used for:
    - Setting up a coordinate system
    - Photo alignment optimization
    - Measuring distances and volumes
    - Marker-based chunk alignment
- More on GCP placing and processing in Agisoft see [intro to the assignment](./2017_Imagery_Processing_assignment_intro.html)

--- -->

## What did we learn?

- What is a general workflow for UAS imagery processing
- How do we transform UAS data into orthophoto, DSM, 3D model, and point cloud
<!-- - How to process the data in Agisoft Metashape Professional and how to set proper parameters in the program -->
